{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "\n",
    "class PendulumEnv(gym.Env):\n",
    "    metadata = {\"render.modes\": [\"human\", \"rgb_array\"], \"video.frames_per_second\": 30}\n",
    "\n",
    "    def __init__(self, g=10.0):\n",
    "        self.max_speed = 8\n",
    "        self.max_torque = 2.0\n",
    "        self.dt = 0.05\n",
    "        self.g = g\n",
    "        self.m = 1.0\n",
    "        self.l = 1.0\n",
    "        self.viewer = None\n",
    "\n",
    "        high = np.array([1.0, 1.0, self.max_speed], dtype=np.float32)\n",
    "        self.action_space = spaces.Box(\n",
    "            low=-self.max_torque, high=self.max_torque, shape=(1,), dtype=np.float32\n",
    "        )\n",
    "        self.observation_space = spaces.Box(low=-high, high=high, dtype=np.float32)\n",
    "\n",
    "        self.seed()\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def step(self, u):\n",
    "        th, thdot = self.state  # th := theta\n",
    "\n",
    "        g = self.g\n",
    "        m = self.m\n",
    "        l = self.l\n",
    "        dt = self.dt\n",
    "\n",
    "        u = np.clip(u, -self.max_torque, self.max_torque)[0]\n",
    "        self.last_u = u  # for rendering\n",
    "        costs = angle_normalize(th) ** 2 + 0.1 * thdot ** 2 + 0.001 * (u ** 2)\n",
    "\n",
    "        newthdot = (\n",
    "            thdot\n",
    "            + (-3 * g / (2 * l) * np.sin(th + np.pi) + 3.0 / (m * l ** 2) * u) * dt\n",
    "        )\n",
    "        newth = th + newthdot * dt\n",
    "        newthdot = np.clip(newthdot, -self.max_speed, self.max_speed)\n",
    "\n",
    "        self.state = np.array([newth, newthdot])\n",
    "        return self._get_obs(), -costs, False, {}\n",
    "\n",
    "    def reset(self):\n",
    "        high = np.array([np.pi, 1])\n",
    "        self.state = self.np_random.uniform(low=-high, high=high).astype(np.float32)\n",
    "        self.last_u = None\n",
    "        return self._get_obs()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        theta, thetadot = self.state\n",
    "        return np.array([np.cos(theta), np.sin(theta), thetadot])\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        if self.viewer is None:\n",
    "            from gym.envs.classic_control import rendering\n",
    "\n",
    "            self.viewer = rendering.Viewer(500, 500)\n",
    "            self.viewer.set_bounds(-2.2, 2.2, -2.2, 2.2)\n",
    "            rod = rendering.make_capsule(1, 0.2)\n",
    "            rod.set_color(0.8, 0.3, 0.3)\n",
    "            self.pole_transform = rendering.Transform()\n",
    "            rod.add_attr(self.pole_transform)\n",
    "            self.viewer.add_geom(rod)\n",
    "            axle = rendering.make_circle(0.05)\n",
    "            axle.set_color(0, 0, 0)\n",
    "            self.viewer.add_geom(axle)\n",
    "            fname = path.join(path.dirname(__file__), \"assets/clockwise.png\")\n",
    "            self.img = rendering.Image(fname, 1.0, 1.0)\n",
    "            self.imgtrans = rendering.Transform()\n",
    "            self.img.add_attr(self.imgtrans)\n",
    "\n",
    "        self.viewer.add_onetime(self.img)\n",
    "        self.pole_transform.set_rotation(self.state[0] + np.pi / 2)\n",
    "        if self.last_u:\n",
    "            self.imgtrans.scale = (-self.last_u / 2, np.abs(self.last_u) / 2)\n",
    "\n",
    "        return self.viewer.render(return_rgb_array=mode == \"rgb_array\")\n",
    "\n",
    "    def close(self):\n",
    "        if self.viewer:\n",
    "            self.viewer.close()\n",
    "            self.viewer = None\n",
    "\n",
    "\n",
    "def angle_normalize(x):\n",
    "    return ((x + np.pi) % (2 * np.pi)) - np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: float32\n",
      "Real observation dtype: float32\n"
     ]
    }
   ],
   "source": [
    "env = PendulumEnv()\n",
    "print(f\"Observation space: {env.observation_space.dtype}\")\n",
    "print(f\"Real observation dtype: {env.reset().dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-2.], [2.], (1,), float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, _, _, _ = env.step([0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Continuous_MountainCarEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        The agent (a car) is started at the bottom of a valley. For any given\n",
    "        state the agent may choose to accelerate to the left, right or cease\n",
    "        any acceleration.\n",
    "    Observation:\n",
    "        Type: Box(2)\n",
    "        Num    Observation               Min            Max\n",
    "        0      Car Position              -1.2           0.6\n",
    "        1      Car Velocity              -0.07          0.07\n",
    "    Actions:\n",
    "        Type: Box(1)\n",
    "        Num    Action                    Min            Max\n",
    "        0      the power coef            -1.0           1.0\n",
    "        Note: actual driving force is calculated by multipling the power coef by power (0.0015)\n",
    "    Reward:\n",
    "         Reward of 100 is awarded if the agent reached the flag (position = 0.45) on top of the mountain.\n",
    "         Reward is decrease based on amount of energy consumed each step.\n",
    "    Starting State:\n",
    "         The position of the car is assigned a uniform random value in\n",
    "         [-0.6 , -0.4].\n",
    "         The starting velocity of the car is always assigned to 0.\n",
    "    Episode Termination:\n",
    "         The car position is more than 0.45\n",
    "         Episode length is greater than 200\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\", \"rgb_array\"], \"video.frames_per_second\": 30}\n",
    "\n",
    "    def __init__(self, goal_velocity=0):\n",
    "        self.min_action = -1.0\n",
    "        self.max_action = 1.0\n",
    "        self.min_position = -1.2\n",
    "        self.max_position = 0.6\n",
    "        self.max_speed = 0.07\n",
    "        self.goal_position = (\n",
    "            0.45  # was 0.5 in gym, 0.45 in Arnaud de Broissia's version\n",
    "        )\n",
    "        self.goal_velocity = goal_velocity\n",
    "        self.power = 0.0015\n",
    "\n",
    "        self.low_state = np.array(\n",
    "            [self.min_position, -self.max_speed], dtype=np.float32\n",
    "        )\n",
    "        self.high_state = np.array(\n",
    "            [self.max_position, self.max_speed], dtype=np.float32\n",
    "        )\n",
    "\n",
    "        self.viewer = None\n",
    "\n",
    "        self.action_space = spaces.Box(\n",
    "            low=self.min_action, high=self.max_action, shape=(1,), dtype=np.float32\n",
    "        )\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=self.low_state, high=self.high_state, dtype=np.float32\n",
    "        )\n",
    "\n",
    "        self.seed()\n",
    "        self.reset()\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        position = self.state[0]\n",
    "        velocity = self.state[1]\n",
    "        force = min(max(action[0], self.min_action), self.max_action)\n",
    "\n",
    "        velocity += force * self.power - 0.0025 * math.cos(3 * position)\n",
    "        if velocity > self.max_speed:\n",
    "            velocity = self.max_speed\n",
    "        if velocity < -self.max_speed:\n",
    "            velocity = -self.max_speed\n",
    "        position += velocity\n",
    "        if position > self.max_position:\n",
    "            position = self.max_position\n",
    "        if position < self.min_position:\n",
    "            position = self.min_position\n",
    "        if position == self.min_position and velocity < 0:\n",
    "            velocity = 0\n",
    "\n",
    "        # Convert a possible numpy bool to a Python bool.\n",
    "        done = bool(position >= self.goal_position and velocity >= self.goal_velocity)\n",
    "\n",
    "        reward = 0\n",
    "        if done:\n",
    "            reward = 100.0\n",
    "        reward -= math.pow(action[0], 2) * 0.1\n",
    "\n",
    "        self.state = np.array([position, velocity])\n",
    "        return self.state, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = np.array([self.np_random.uniform(low=-0.6, high=-0.4), 0]).astype(np.float32)\n",
    "        return np.array(self.state)\n",
    "\n",
    "    def _height(self, xs):\n",
    "        return np.sin(3 * xs) * 0.45 + 0.55\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        screen_width = 600\n",
    "        screen_height = 400\n",
    "\n",
    "        world_width = self.max_position - self.min_position\n",
    "        scale = screen_width / world_width\n",
    "        carwidth = 40\n",
    "        carheight = 20\n",
    "\n",
    "        if self.viewer is None:\n",
    "            from gym.envs.classic_control import rendering\n",
    "\n",
    "            self.viewer = rendering.Viewer(screen_width, screen_height)\n",
    "            xs = np.linspace(self.min_position, self.max_position, 100)\n",
    "            ys = self._height(xs)\n",
    "            xys = list(zip((xs - self.min_position) * scale, ys * scale))\n",
    "\n",
    "            self.track = rendering.make_polyline(xys)\n",
    "            self.track.set_linewidth(4)\n",
    "            self.viewer.add_geom(self.track)\n",
    "\n",
    "            clearance = 10\n",
    "\n",
    "            l, r, t, b = -carwidth / 2, carwidth / 2, carheight, 0\n",
    "            car = rendering.FilledPolygon([(l, b), (l, t), (r, t), (r, b)])\n",
    "            car.add_attr(rendering.Transform(translation=(0, clearance)))\n",
    "            self.cartrans = rendering.Transform()\n",
    "            car.add_attr(self.cartrans)\n",
    "            self.viewer.add_geom(car)\n",
    "            frontwheel = rendering.make_circle(carheight / 2.5)\n",
    "            frontwheel.set_color(0.5, 0.5, 0.5)\n",
    "            frontwheel.add_attr(\n",
    "                rendering.Transform(translation=(carwidth / 4, clearance))\n",
    "            )\n",
    "            frontwheel.add_attr(self.cartrans)\n",
    "            self.viewer.add_geom(frontwheel)\n",
    "            backwheel = rendering.make_circle(carheight / 2.5)\n",
    "            backwheel.add_attr(\n",
    "                rendering.Transform(translation=(-carwidth / 4, clearance))\n",
    "            )\n",
    "            backwheel.add_attr(self.cartrans)\n",
    "            backwheel.set_color(0.5, 0.5, 0.5)\n",
    "            self.viewer.add_geom(backwheel)\n",
    "            flagx = (self.goal_position - self.min_position) * scale\n",
    "            flagy1 = self._height(self.goal_position) * scale\n",
    "            flagy2 = flagy1 + 50\n",
    "            flagpole = rendering.Line((flagx, flagy1), (flagx, flagy2))\n",
    "            self.viewer.add_geom(flagpole)\n",
    "            flag = rendering.FilledPolygon(\n",
    "                [(flagx, flagy2), (flagx, flagy2 - 10), (flagx + 25, flagy2 - 5)]\n",
    "            )\n",
    "            flag.set_color(0.8, 0.8, 0)\n",
    "            self.viewer.add_geom(flag)\n",
    "\n",
    "        pos = self.state[0]\n",
    "        self.cartrans.set_translation(\n",
    "            (pos - self.min_position) * scale, self._height(pos) * scale\n",
    "        )\n",
    "        self.cartrans.set_rotation(math.cos(3 * pos))\n",
    "\n",
    "        return self.viewer.render(return_rgb_array=mode == \"rgb_array\")\n",
    "\n",
    "    def close(self):\n",
    "        if self.viewer:\n",
    "            self.viewer.close()\n",
    "            self.viewer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Continuous_MountainCarEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.58465034,  0.00092777])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step([0.])[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (crowd)",
   "language": "python",
   "name": "crowd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
